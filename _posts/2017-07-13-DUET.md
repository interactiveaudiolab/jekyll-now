---
published: false
layout: post
title: DUET
---

<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"> </script> 

The first source separation algorithm we're going to explore in the _nussl blog_ is the Degenerate Unmixing Extraction Technique, or DUET. This algorithm was first proposed by Scott Rickard, et al [1, 2, 3] in the early 2000s. As with many of the algorithms that we will examine in this blog, DUET has a number of different variants; here we will explore the method as outlined in Rickard's 2007 chapter from [Blind Speech Separation](http://www.cs.northwestern.edu/~pardo/courses/casa/papers/DuetSourceSeparationTutorial.pdf).

As you can problably guess by its name, DUET requires _two_ slightly different recordings of the same mixture. Luckily, this is often the case in stereo recordings. In a nutshell, DUET separates sources by examining differences in attenuation (or softness) and delay between each channel in a stereo mixture. This mirrors the auditory systems in many animals (humans included) and is one of the many source separation algorithms that echoes psychoacoustic processes.

    
## The biological analogy

If you're reading this, we're assuming that you are a human. As such, the odds are high that you have one ear on each side of your head. If that's true, then congratulations are in order, because by arranging the outermost part of your auditory system like this you've given yourself the physical part of the biological toolkit that enables your innate source separation superpowers. Great job! While much of the neurological machinery that drives source separation in your brain is still a mystery, understanding the physics that underly this tangible part of your source separation powers is so easy that even some simpleton computer scientists [5] can explain it.

[[VISUAL PARALLAX IMG]]

Your ears work in a related way to your eyes. To visually determine how far away an object is from you, your brain has a built-in understanding of parallax; your brain has an understanding of how far apart your eyes are, what angle they currently pointing towards, and goemetry. It conglomerates all of this information to give you real time depth perception. 

Your brain has a similar mechanism for understanding where sonic objects are in an auditory field. Because you're a human, I'm sure you know by now that as you move further away from the source of a sound two things happen: 1) the sound becomes quieter, and 2) the sound takes longer to reach you.

[[SOUND GETTING QUIETER AND TAKING LONGER IMG]]

Somewhere inside your brain there is 


...




## Assumptions of DUET

1. Stereo mixture

    DUET, as mentioned earlier, requires that there be a stereo mixture, but it can separate an arbitrarily number of sources from that stereo mixture.

2. W-Disjoint Orthogonality

    DUET is predicated on the concept of W-Disjoint Orthogonality, or WDO. WDO asserts that every single time-frequency point only contains non-negligable energy from a _single_ source.
    
3. Anechoic

    DUET also assumes that the stereo mixture has little or no reverb, delay, echoes, etc. Because DUET relies on minute differences in delay between the two channels, adding reverb or delay in a mixture is like putting a stick in the spokes of your bicycle.
    
4. Sources don't move

    The last assumption that DUET makes is that the sources don't move within the stereo field. When a source moves it can affect both the delay between channels and the attenuation between channels. Both of these, as stated, are bad for DUET.
    
## How DUET works


## 


[5] AKA, the authors of this blog.
